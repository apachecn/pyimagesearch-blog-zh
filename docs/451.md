# 什么是人脸识别？

> 原文：<https://pyimagesearch.com/2021/05/01/what-is-face-recognition/>

在本教程中，您将了解人脸识别，包括:

*   人脸识别的工作原理
*   人脸识别*与人脸检测*有何不同
*   人脸识别算法的历史
*   当今用于人脸识别的最先进算法

下周我们将开始实施这些人脸识别算法。

**要了解人脸识别，*继续阅读。***

## **什么是人脸识别？**

人脸识别是在图像中拍摄一张人脸并实际上*识别*该人脸属于谁的过程。因此，面部识别是一种**身份识别的形式。**

早期的人脸识别系统依赖于从图像中提取的早期版本的面部标志，如眼睛、鼻子、颧骨和下巴的相对位置和大小。然而，这些系统通常非常主观，并且容易出错，因为这些面部量化是由运行面部识别软件的计算机科学家和管理员手动提取的。

随着机器学习算法变得更加强大和计算机视觉领域的成熟，人脸识别系统开始利用特征提取和分类模型来识别图像中的人脸。

这些系统不仅是非主观的，而且是自动的——不需要人工标记人脸。我们简单地从面部提取特征，训练我们的分类器，然后用它来识别后续的面部。

最近，我们已经开始[利用深度学习算法进行人脸识别](https://pyimagesearch.com/2018/09/24/opencv-face-recognition/)。FaceNet 和 OpenFace 等最先进的人脸识别模型依赖于一种叫做**暹罗网络**的专门深度神经网络架构。

这些神经网络能够获得曾经被认为不可能的人脸识别精度(而且它们可以在数据少得惊人的情况下达到这种精度)。

### **人脸** ***识别*** **与人脸** ***检测有何不同？***

我经常看到新的计算机视觉和深度学习从业者混淆人脸检测和人脸识别之间的区别，有时(并不正确地)互换使用这两个术语。

**人脸检测和人脸识别都是** ***截然不同的*** **算法** — ***人脸检测******会告诉你*******在给定的图像/帧中一张人脸是属于谁的(而不是*****而*****

 ****让我们进一步分析一下:

与 [**人脸检测**](https://pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/) 不同，后者是简单的*检测图像或视频流中人脸的存在*的过程，**人脸识别**采用从定位阶段检测到的人脸，并试图识别*该人脸属于*谁。因此，人脸识别可以被认为是一种身份识别方法，我们在安全和监控系统中大量使用。

根据定义，人脸识别需要人脸检测，因此我们可以将人脸识别视为两个阶段的过程。

*   **阶段#1:** 使用诸如 Haar 级联、HOG +线性 SVM、深度学习或任何其他可以定位人脸的算法来检测图像或视频流中人脸的存在。
*   **阶段#2:** 获取定位阶段检测到的每一张人脸，并识别它们中的每一张——这是我们实际上为人脸指定名称的地方。

在本教程的剩余部分，我们将回顾人脸识别的快速历史，然后介绍人脸识别算法和技术，包括特征脸，用于人脸识别的局部二进制模式(LBPs)，暹罗网络，FaceNet 等。

### **人脸识别简史**

人脸识别现在似乎无处不在(大多数智能手机和主要社交媒体平台都在实施)，但在 20 世纪 70 年代之前，人脸识别通常被视为科幻小说，与超未来时代的电影和书籍隔离开来。简而言之，人脸识别是一个幻想，它是否会成为现实还不清楚。

这一切都在 1971 年改变了，当时 Goldstein 等人发表了 [*人脸识别*](https://ieeexplore.ieee.org/document/1450184) 。作为人脸识别的初步尝试，这种方法提出了 21 个主观面部特征，如头发颜色和嘴唇厚度，来识别照片中的人脸。

这种方法的最大缺点是，21 个测量值(除了高度主观之外)是手动计算的*——这是计算机科学社区中的一个明显缺陷，该社区正在快速走向无监督计算和分类(至少在人类监督方面)。*

 *然后，十多年后，在 1987 年，西罗维奇和科比发表了他们的开创性工作， [*一种用于描述人脸特征的低维程序*](https://pyimagesearch.com/wp-content/uploads/2021/05/kirby_1987.pdf) ，随后在 1991 年，特克和彭特兰使用特征脸 *进行了 [*人脸识别。*](https://sites.cs.ucsb.edu/~mturk/Papers/mturk-CVPR91.pdf)*

Sirovich 和 Kirby 以及 Turk 和 Pentland 证明了一种称为[主成分分析](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA)的标准线性代数降维技术可以用于使用小于 100 维的特征向量来识别人脸。

此外，“主成分”(即特征向量，或“特征脸”)可用于从原始数据集重建人脸。这意味着人脸可以被表示(并最终被识别)为特征脸的线性组合:

*查询脸=特征脸#1 的 36%+-特征脸#2 的 8%…+特征脸 N 的 21%*

继 Sirovich 和 Kirby 在 20 世纪 80 年代后期的工作之后，对人脸识别的进一步研究爆发了——另一种流行的基于线性代数的人脸识别技术利用了[线性判别分析](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)。基于 LDA 的人脸识别算法俗称**鱼脸**。

基于特征的方法，例如用于人脸识别的[](https://pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/)****局部二进制模式也已经被提出，并且仍然在现实世界的应用中大量使用:****

 ****深度学习现在负责人脸识别中*前所未有的*准确性。称为**暹罗网络**的专门架构用一种特殊类型的数据训练，称为**图像三元组**。然后，我们计算、监控并试图最小化我们的**三重损失**，从而最大化人脸识别的准确性。

流行的深度神经网络人脸识别模型有 [FaceNet](https://arxiv.org/abs/1503.03832) 和 [OpenFace](http://cmusatyalab.github.io/openface/) 。

### **特征脸**

本征脸算法使用主成分分析来构建人脸图像的低维表示。

这个过程包括收集一个人脸数据集，其中每个人都有多个我们想要识别的人脸图像(就像在执行图像分类时，我们想要识别一个图像类别的多个训练示例)。

给定这个人脸图像的数据集，假设它们具有相同的宽度、高度，并且理想地，它们的眼睛和面部结构在相同的 *(x，y)*-坐标上对齐，我们应用数据集的特征值分解，保留具有最大对应特征值的特征向量。

给定这些特征向量，人脸就可以表示为 Sirovich 和 Kirby 所说的**特征脸的线性组合。**

可以通过计算特征脸表示之间的欧几里德距离并将人脸识别视为 k-最近邻分类问题来执行人脸识别，但是，我们通常倾向于对特征脸表示应用更高级的机器学习算法。

如果您对线性代数术语或特征脸算法的工作原理感到有点不知所措，不要担心，我们将在本系列人脸识别教程的后面详细介绍特征脸算法。

### **用于人脸识别的 LBPs】**

本征脸算法依靠 PCA 来构建人脸图像的低维表示，而局部二进制模式(LBPs)方法，顾名思义，依靠特征提取。

Ahonen 等人在他们 2004 年的论文 [*中首次介绍了使用局部二进制模式*](https://link.springer.com/chapter/10.1007/978-3-540-24670-1_36) 进行人脸识别，他们的方法建议将人脸图像分成大小相等的单元的 *7×7* 网格:

通过将图像分成单元，我们可以将*位置*引入到我们最终的特征向量中。此外，一些单元格被加权，使得它们对整体表示的贡献*更多*。**与网格中心的细胞(包含眼睛、鼻子和嘴唇结构)相比，角落的细胞携带的识别面部信息较少。**

最后，我们连接来自 49 个细胞的加权 LBP 直方图以形成我们的最终特征向量。

使用![\chi^{2}](img/dea0bac5ece00bdd51051fcc94abb71f.png "\chi^{2}")通过 k-NN 分类进行实际的人脸识别

distance between the query image and the dataset of labeled faces — since we are comparing histograms, the ![\chi^{2}](img/dea0bac5ece00bdd51051fcc94abb71f.png "\chi^{2}")distance is a better choice than the Euclidean distance.

虽然用于人脸识别的特征脸和 LBP 都是用于人脸识别的相当简单的算法，但是基于特征的 LBP 方法往往对噪声更有弹性(因为它不对原始像素强度本身进行操作)，并且通常会产生更好的结果。

我们将在本系列教程的后面详细实现 LBPs 人脸识别。

### **基于深度学习的人脸识别**

深度学习几乎影响了计算机科学的每个方面和子领域。人脸识别也没什么不同。

多年来，LBP 和特征脸/鱼脸被认为是人脸识别的最新技术。这些技术很容易被愚弄，在研究实验室/受控环境之外，准确性很差。

深度学习改变了这一切。专门的神经网络架构和训练技术，包括**暹罗网络**、**图像三元组**和**三元组丢失、**使研究人员能够获得曾经被认为不可能的人脸识别准确性。

这些方法比以前的技术更加精确和稳健。尽管神经网络被认为是数据饥渴的野兽，但暹罗网络允许我们用很少的数据训练这些最先进的模型。

如果你有兴趣了解更多基于深度学习的人脸识别，我建议你阅读 PyImageSearch 上的以下指南:

1.  [*人脸识别用 OpenCV、Python 和深度学习*](https://pyimagesearch.com/2018/06/18/face-recognition-with-opencv-python-and-deep-learning/)
2.  [*OpenCV 人脸识别*](https://pyimagesearch.com/2018/09/24/opencv-face-recognition/)
3.  [*树莓派人脸识别*](https://pyimagesearch.com/2018/06/25/raspberry-pi-face-recognition/)
4.  [*树莓 Pi 和 Movidius NCS 人脸识别*](https://pyimagesearch.com/2020/01/06/raspberry-pi-and-movidius-ncs-face-recognition/)

## **总结**

在本教程中，我们了解到人脸识别是一个分为两个阶段的过程，包括:

1.  人脸检测和人脸感兴趣区域的提取
2.  识别，在这里我们识别出*这张脸属于谁*

从那里，我们回顾了人脸识别算法的历史，包括:

*   由研究人员手动标记的粗糙的(通常是主观的)面部标志
*   基于线性代数的技术，如特征面和鱼面
*   用于人脸识别的 LBPs
*   基于深度学习的模型，包括 FaceNet 和 OpenFace

本系列的下一篇教程将介绍如何用 OpenCV 实现 Eigenfaces。

**要下载这篇文章的源代码(并在未来教程在 PyImageSearch 上发布时得到通知)，** ***只需在下面的表格中输入您的电子邮件地址！************