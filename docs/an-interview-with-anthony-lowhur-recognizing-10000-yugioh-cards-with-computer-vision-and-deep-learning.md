# 对 Anthony Lowhur 的采访——用计算机视觉和深度学习识别 10，000 张 Yugioh 卡

> 原文：<https://pyimagesearch.com/2021/03/03/an-interview-with-anthony-lowhur-recognizing-10000-yugioh-cards-with-computer-vision-and-deep-learning/>

在这篇博文中，我采访了计算机视觉和深度学习工程师 Anthony Lowhur。Anthony 分享了他用来构建能够识别 10，000+ Yugioh 交易卡的计算机视觉和深度学习系统的算法和技术。

我喜欢安东尼的项目——我希望几年前就有了它。

当我还是个孩子的时候，我喜欢收集交易卡。我有很多活页夹，里面装满了棒球卡、篮球卡、足球卡、口袋妖怪卡等等。我甚至有*侏罗纪公园*的交易卡！

我甚至无法开始估算我花了多少时间整理我的卡片，先按团队，再按职位，最后按字母顺序。

然后，当我完成后，我会想出一个“新的更好的方法”来整理卡片，并重新开始。在我年轻的时候，我在探索一个八岁孩子能给卡片分类的算法复杂性。充其量，我可能只有 O(N² ，所以我还有相当大的提升空间。

安东尼将卡片识别提升到了一个全新的水平。用你的智能手机，你可以拍一张 Yugioh 交易卡的照片，然后立刻认出它。这种应用程序对于以下方面非常有用:

*   想要快速确定其收藏中是否已有交易卡的收藏者
*   想要建立游戏卡数据库的档案管理员，游戏卡的属性，生命值，伤害等。(即，在识别后对卡进行 OCR)
*   Yugioh 玩家不仅希望*识别*一张卡片，还希望*翻译*它(如果你不能阅读日语，但希望同时玩英语和日语卡片，或者反之亦然，这非常有用)。

Anthony 使用几种计算机视觉和深度学习算法构建了他的 Yugioh 卡识别系统，包括:

*   暹罗网络
*   三重损失
*   最终重新排序的关键点匹配(这是一个*特别是*聪明的技巧，你会想了解更多)

请和我一起坐下来和安东尼讨论他的项目。

**学习如何用计算机视觉和深度学习识别 Yugioh 牌，** ***继续看就好。***

## **对 Anthony Lowhur 的采访——用计算机视觉和深度学习识别 10，000 张 Yugioh 卡**

阿德里安:欢迎你，安东尼！非常感谢你能来。很高兴您能来到 PyImageSearch 博客。

安东尼:谢谢你邀请我。很荣幸来到这里。

* * *

阿德里安:介绍一下你自己，你在哪里工作，你的工作是什么？

Anthony: 我目前是一名全职的计算机视觉(CV)和机器学习(ML)工程师，离华盛顿 DC 不远，我设计和构建供客户使用的人工智能(AI)系统。我实际上是不久前从大学毕业并获得学士学位的，所以我对这个行业还比较陌生。

* * *

**Adrian:** 你最初是如何对计算机视觉和深度学习产生兴趣的？

安东尼:当我开始了解被称为 DARPA 大挑战的自动驾驶汽车比赛时，我还是一名高中生。这本质上是不同大学和研究实验室之间建造自动驾驶汽车在沙漠中相互比赛的竞争。赢得比赛的汽车来自斯坦福大学，由巴斯蒂安·特龙领导。

随后，巴斯蒂安·特龙继续领导谷歌 X 项目，研发无人驾驶汽车。以前被认为是科幻小说一部分的东西现在正在成为现实，这一事实真的激励了我，从那以后我开始学习计算机视觉和深度学习。我开始在 CV 和 ML 中做个人项目，并开始在 REUs(本科生的研究经历)进行 CV/ML 研究，一切都从那里开始。

* * *

**Adrian:** 你刚刚开发完一个可以自动识别 10，000+ Yugioh 卡的计算机视觉系统。出色的工作！是什么激发了你创建这样一个系统？这样的系统如何帮助 Yugioh 玩家和卡片收藏者？

**Anthony:** 所以就有了我小时候看的一个叫 [Yugioh](https://en.wikipedia.org/wiki/Yu-Gi-Oh!) 的纸牌游戏和电视剧。直到今天，它一直占据着我的心灵，它让我想起了每天放学后坐在电视机前的时光。

我添加 AI 是因为制造它实际上是一个更大项目的先决条件，**是一个 Yugioh duel disk** 。

你可以在这里阅读更多关于它的信息:[我做了一个功能性的双盘(由 AI 提供动力)](https://www.reddit.com/r/yugioh/comments/idagc9/i_made_a_functional_duel_disk_powered_by_ai/)。

这是一个演示视频:

简而言之，这是一个让你在几英尺之外决斗的浮华设备，它在电视剧中出现过。我认为这是一个有趣的项目，可以制作并展示给其他 Yugioh 粉丝，这足以激励我继续这个项目，直到原型完成。

除了创建 duel disk 之外，还有人来找我，说他们有兴趣让它组织他们的 Yugioh 卡收藏，或者为他们的一个应用程序创意提供动力。虽然有一些不完善的地方，但它目前在 GitHub 上是开源的，所以人们有机会试用它。

* * *

阿德里安:你是如何建立 Yugioh 卡的数据集的？最后你每张卡片上有多少示例图片？

安东尼:首先，我必须提取我们的数据集。卡数据集是从 API 中检索的。卡片的全尺寸版本被使用:[游戏王！API 指南–ygo prodeck](https://db.ygoprodeck.com/api-guide/)。

该 API 用于将所有 Yugioh 卡(10，856 张卡)下载到我们的机器上，以将它们转换为数据集。

但是，主要问题是，大多数卡片只包含一种卡牌艺术(而其他包含多种卡牌艺术的卡片，其卡牌艺术彼此之间有显著差异)。在机器学习的意义上，本质上，有超过 10，000 个类，其中每个类只包含一个图像。

这是一个问题，因为传统的深度学习方法在少于 100 幅图像的数据集上表现不佳，更不用说每类一幅图像了。我做了一万节课。

因此，我不得不使用一次性学习来解决这个问题。一次性学习是一种比较两个图像之间的相似性而不是预测一个类别的方法。

* * *

**阿德里安:**基本上每张卡片只有*一张*样本图像，你没有多少东西可以从神经网络中学到。你应用了任何类型的数据增强吗？如果是，您使用了什么类型的数据增强？

Anthony: 虽然我们每个类只处理一个图像，但我们想看看我们是否能从这个模型中获得尽可能多的鲁棒性。因此，我们执行图像增强来创建每个卡片艺术的多个版本，但有细微的差异(亮度变化、对比度变化、偏移等)。).这将为我们的网络提供更多的数据，让我们的模型更好地泛化。

* * *

阿德里安:现在你的磁盘上有一个 Yugioh 卡的数据集。你是如何选择深度学习模型架构的？

安东尼:最初，我为暹罗网络做了一个简单的浅层网络实验，作为衡量的基准。

不足为奇的是，该网络表现不佳。网络不适合我给它的训练数据，所以我想解决这个问题。向网络添加更多层是解决方案的补救措施之一，因此我尝试了 [Resnet101](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet101) ，这是一个以其巨大的层深度而闻名的网络。这最终成为我需要的架构，因为它的性能明显更好，并且达到了我的精度目标。因此，这就是最终的主要架构。

当然，如果我以后想让单个图像预测的推断时间更快，我总是可以求助于使用像 [VGG16](https://neurohive.io/en/popular-networks/vgg16/) 这样的层数更少的网络。

* * *

**Adrian:** 您显然做了充分的准备，知道暹罗网络是这个项目的最佳架构选择。你使用标准的“香草”暹罗网络图像对吗？还是用了三胞胎和三胞胎损失来训练你的网络？

安东尼:最初，我尝试了主要使用一对图像进行比较的香草暹罗网络，尽管它的局限性开始显现。

结果，我研究了其他架构，最终发现了三元组网络。它主要不同于暹罗网络，因为它使用三个图像而不是两个，并使用不同的损失函数，称为三重损失。它主要能够在训练过程中使用正负锚来操纵图像之间的距离。因此，它实现起来相对较快，并且恰好是最终的解决方案。

* * *

**Adrian:** 在这一点上，你有了一个深度学习模型，它可以*识别*输入的 Yugioh 卡，或者*非常接近*返回前 10 名结果中的正确 Yugioh 卡。你是如何进一步提高准确性的？你使用了某种图像重新排序算法吗？

Anthony: 因此，尽管由 resnet101 制成的三联体网络显示出显著的改进，但似乎存在一些边界情况，在这些情况下，它不能预测正确的秩 1 类，但相对接近。为了克服这一点，ORB(面向快速和旋转简短)算法被用作支持。ORB 是一种在图像内搜索特征点的算法，因此，如果两幅图像完全相同，则这两幅图像应该具有相同数量的特征点。

该算法为我们的一次性学习方法提供了支持。一旦我们的神经网络在所有 10，000 张卡片上生成分数并对它们进行排名，我们的 ORB 就会获得 top- *N* 卡片排名(例如，前 50 张卡片)并计算图像上的 ORB 点数。然后，将原始相似性得分和 ORB 点数输入公式，以获得最终加权相似性得分。比较前- *N* 张牌的加权分数，并将分数重新排列到它们的最终排名。

**图 3** 显示了一个先前具有挑战性的边缘案例，在该案例中，我们在不同的对比度设置下比较了顶牌(黑暗魔术师)的两幅图像。本来没有 ORB 匹配支持就失败了，但是考虑到头脑中特征点的数量，可以得到更准确的排名。

经过一些实验和对某些值的调整，我显著提高了正确预测的数量。

* * *

**Adrian:** 在您的实验中，您发现即使输入图像中很小的偏移/平移也会导致准确性显著下降，这意味着您的卷积神经网络(CNN)没有很好地处理平移。你是如何克服这个问题的？

安东尼:处理这个问题的确很有趣，也很棘手。现代 CNN 在本质上不是平移不变的，即使很小的翻译也会使其混淆。我们正在处理的数据非常少，并且该算法依赖于将特征图放在一起进行比较来进行预测，这一事实进一步强调了这一点。

*   在左侧，原始图像与相同但向右平移的图像进行比较(我们跳了 0.71 点)。
*   在中间的图像中，原始图像与向右上方平移的同一图像进行比较。
*   在右侧图像中，原始图像与向右上方平移的同一图像进行比较。

这个问题表明，我们的模型对轻微的错位非常敏感，并阻止我们的模型实现其全部潜力。

我的第一种方法是通过在数据扩充过程中添加更多的翻译来简单地扩充数据。然而，这还不够，我必须寻找其他方法。

结果，我发现一些研究创造了用于解决类似问题的[模糊池算法](https://arxiv.org/pdf/1904.11486.pdf)。模糊池是一种用于解决 CNN 不是 sift 不变的问题的方法，并且应用于每个卷积层的末端。

* * *

**阿德里安:**你的算法本质上是为你数据集中的*所有*卡片生成一个相似性得分。在比较 10，000 多张输入 Yugioh 卡时，您是否遇到过任何速度或效率问题？

安东尼:因此，在这一点上，我有一个模型能够以合理的准确度生成每张卡片的相似性得分。**现在我所要做的就是为我们的输入图像和所有我想要比较的卡片生成相似性分数。**

如果我测量我的模型的推理时间，我们可以看到，通过我们的三元 Resnet 架构传递一幅图像需要大约 0.12 秒，以及 0.08 秒的图像预处理步骤。从表面上看，这听起来不错，但是请记住，我们必须对数据集中的所有卡片都这样做。**问题是，我们需要将超过 10，000 张卡片与输入进行比较，并生成分数。**

因此，如果我们计算生成相似性得分所需的秒数以及数据集中卡片的总数(10，856)，我们会得到:

(0.12+0.08) * 10，856 = 2171.2 秒

2171.2/60 = 36.2 分钟

为了预测单个输入图像是什么，我们必须等待 30 分钟以上。结果，这并没有使我们的模型实用。

为了解决这个问题，我最终提前预计算了所有 10，000 张卡的输出卷积特征图，并将其存储在一个字典中。字典的伟大之处在于，从字典中检索预先计算的特征图将是恒定的时间( *O(1)* time)。因此，随着数据集中卡片数量的增加，这将是一项不错的工作。

因此，在训练之后，我们迭代超过 10，000 张卡片，将它们输入我们的三元组网络，以获得输出卷积特征图，并将其存储在我们的字典中。我们只是在预测阶段迭代我们的新字典，而不是让我们的模型执行 10，000 次正向传播。

因此，之前 36 分钟的单幅图像预测时间已经显著减少了近 5 秒。这导致了更易于管理的模型。

* * *

**Adrian:** 你是如何测试和评估你的 Yugioh 卡识别系统的准确性的？

安东尼:总的来说，我主要处理两种类型的数据集。

我使用了一个数据集进行训练，其中官方卡片艺术图像来自 ygoprodeck(数据集 A)以及野外卡片的真实照片(数据集 B)，这些照片是由相机拍摄的卡片照片。数据集 B 本质上是我用来取得长期成功的最终测试数据集。

人工智能/机器学习模型在卡片的真实照片上进行测试(有袖子和没有袖子的卡片)。这是数据集 b 的一个例子。

这些类型的图像是我最终希望我的人工智能分类器能够成功地让相机指向你的卡，并能够识别它。

然而，由于购买超过 10，000 张卡片并给它们拍照并不现实，我尝试了退而求其次的方法:在 Yugioh 卡片的在线数据集上进行测试，并人工添加具有挑战性的修改。修改包括改变亮度、对比度和剪切，以模拟现实生活中不同照明/照片质量场景下的 Yugioh 卡(数据集 A)。

以下是数据集中的一些输入图像和卡片艺术:

这是最终的结果:

以下是卡片识别器的几个应用示例:

在 Yugioh 的游戏中，人工智能分类器对所有卡片的准确率达到了 99%。

这本来是一个快速的项目，所以我很高兴的进展。我可能会尝试看看我是否可以收集更多的 Yugioh 卡，并尝试改善系统。

* * *

阿德里安:你项目的下一步是什么？

Anthony: 肯定有一些不完美的地方会阻碍我的模型发挥出它的全部潜力。

用于训练的数据集是来自 ygoprodeck 的官方卡片艺术图像(数据集 A)，而不是野外卡片的真实照片(数据集 B)，后者是由相机拍摄的卡片照片。

99%的准确性结果来自数据集 A 上的训练和测试，而训练的模型也在数据集 B 上的一些卡片上进行测试。然而，我们没有数据集 B 的大量数据来对其执行实际训练或甚至大规模评估。这个报告证明了我们的模型可以通过数据集 A 学习 Yugioh 卡，并有可能在数据集 B 上取得成功，数据集 B 是我们模型的更真实和自然的图像集目标。建立一个数据收集基础设施来大规模收集数据集 B 的图像样本将极大地推进该项目，并有助于确认模型的强度。

这个程序也没有合适的对象检测器，只是使用简单的图像处理方法( [4 点变换](https://pyimagesearch.com/2014/08/25/4-point-opencv-getperspective-transform-example/))来获得卡片的边界框并对齐它。使用像 [YOLO(你只看一次)](https://towardsdatascience.com/yolo-you-only-look-once-real-time-object-detection-explained-492dc9230006)这样合适的物体检测器将是理想的，这也将有助于检测多个演示卡。

更精确和更真实的图像增强方法将有助于添加眩光、更自然的光照和扭曲，这可能有助于我的模型从数据集 A 适应甚至更真实的图像。

* * *

**Adrian:** 你从 2017 年开始就是 PyImageSearch 的读者和客户了！谢谢你支持 PyImageSearch 和我。你有哪些 PyImageSearch [的书籍和课程](https://pyimagesearch.com/books-and-courses/)？他们是如何帮助你为这个项目的完成做准备的？

**Anthony:** 我目前拥有用于计算机视觉的[*深度学习 for Python*](https://pyimagesearch.com/deep-learning-computer-vision-python-book/) bundle 以及用于计算机视觉的*[Raspberry Pi](https://pyimagesearch.com/raspberry-pi-for-computer-vision/)*本书。

从读你的书到我尝试这个项目的时间间隔是 3 年左右，所以一路上我经历了很多事情，从各种渠道获得了很多东西。

PyImageSearch 博客和使用 Python 捆绑包的*计算机视觉深度学习已经成为我巨大旅程的一部分，教会了我并加强了我的计算机视觉和深度学习基础。多亏了这个包，我知道了更多像 Resnet 这样的架构和像迁移学习这样的方法。它们帮助我形成了基础知识，使我能够深入到更高级的概念中，而这些概念是我通常不会经历的。*

当我开始着手 Yugioh 项目时，我在项目中应用的大多数概念对我来说已经是第二天性了。他们给了我信心去计划和试验模型，直到我得到满意的结果。

* * *

**Adrian:** 你会向其他尝试学习计算机视觉、深度学习和 OpenCV 的初露头角的开发者、学生和研究人员推荐这些书籍和课程吗？

**Anthony:** 当然，像*用 Python 进行计算机视觉深度学习*这样的书有丰富的知识，可以用来启动或加强任何人的计算机视觉和机器学习之旅。它对每个主题的解释，以及代码示例，使其易于理解，并提供了广泛的信息。这无疑加强了我在该领域的基础知识，并帮助我过渡到能够学习更高级的主题，否则我将无法学习。

* * *

**Adrian:** 如果一个 PyImageSearch 的读者想聊聊你的项目，那么和你联系的最佳地点是哪里？

安东尼:与我联系的最好方式是通过我在雅虎网站的电子邮件

你也可以通过 [LinkedIn](https://www.linkedin.com/in/anthony-lowhur-886264b1/) 、 [Medium](https://vanstorm9.medium.com/) 联系我，如果你想看更多我的项目，[可以查看我的 GitHub 页面](http://vanstorm9.github.io/)。

## **总结**

今天我们采访了计算机视觉和深度学习工程师 Anthony Lowhur。

安东尼创造了一个能够识别超过 10，000 张 Yugioh 交易卡的计算机视觉项目。

他的算法工作原理是:

1.  使用数据扩充为每个 Yugioh 卡生成额外的数据样本
2.  根据数据训练一个连体网络
3.  预先计算卡之间的特征图和距离(有助于实现更快的卡识别)
4.  利用关键点匹配来重新排列来自暹罗网络模型的顶部输出

总的来说，他的系统有将近 99%的准确率！

**在 PyImageSearch 上发布以后的教程和采访时，我们会通知您，*只需在下面的表格中输入您的电子邮件地址！***